# Promptimal

## ğŸ—’ï¸ Introduction
  
## ğŸ›  Process

  1. First, a dataset of 2000 complex prompts (HumanEval) was fed into the gpt-3.5-turbo model.
  2. The model was asked to generate an improved the prompt based on 
  3. Developed an automatic prompt engineer by fine-tuning a large language model (Llama2 7b) in Pytorch.
  4. Achieved human-level prompt writing via self-play (automated trial and error).
  5. First to combine the OPRO and Promptbreeder papers with fine-tuning, diverging from reliance on a base model.

![1_DeWuXiLcjn39xo0c6fvsXg](https://github.com/NoahBSchwartz/Promptimal/assets/44248582/3d4059e7-edbc-450c-83ea-53550d1a1396)


## ğŸ‰ Result

## How to Use

View the colab notebook here: 

