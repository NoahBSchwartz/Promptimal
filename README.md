# Promptimal

## 🗒️ Introduction
  
## 🛠 Process

  1. First, a dataset of 2000 complex prompts (HumanEval) was fed into the gpt-3.5-turbo model.
  2. The model was asked to generate an improved the prompt based on 
  3. Developed an automatic prompt engineer by fine-tuning a large language model (Llama2 7b) in Pytorch.
  4. Achieved human-level prompt writing via self-play (automated trial and error).
  5. First to combine the OPRO and Promptbreeder papers with fine-tuning, diverging from reliance on a base model.

![1_DeWuXiLcjn39xo0c6fvsXg](https://github.com/NoahBSchwartz/Promptimal/assets/44248582/3d4059e7-edbc-450c-83ea-53550d1a1396)


## 🎉 Result

## How to Use

View the colab notebook here: 

